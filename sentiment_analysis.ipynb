{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Calvin Zheng\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\scipy\\__init__.py:169: UserWarning: A NumPy version >=1.18.5 and <1.26.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2022-09-08 17:42:49+00:00</td>\n",
       "      <td>This is extremely important. If people buy the...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20620</th>\n",
       "      <td>2022-02-19 16:15:36+00:00</td>\n",
       "      <td>3/ Fed tightening and Russia/Ukraine tensions ...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18621</th>\n",
       "      <td>2022-03-16 20:47:34+00:00</td>\n",
       "      <td>3/ I remain a $TSLA bull, with a) Berlin/Austi...</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14884</th>\n",
       "      <td>2022-04-20 16:21:29+00:00</td>\n",
       "      <td>Just in case something fun happens tonight! $TSLA</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>Tesla, Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62452</th>\n",
       "      <td>2022-01-20 21:21:47+00:00</td>\n",
       "      <td>Spotted:  Ross Gerber watching $NFLX get Chama...</td>\n",
       "      <td>NFLX</td>\n",
       "      <td>Netflix, Inc.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Date  \\\n",
       "1577   2022-09-08 17:42:49+00:00   \n",
       "20620  2022-02-19 16:15:36+00:00   \n",
       "18621  2022-03-16 20:47:34+00:00   \n",
       "14884  2022-04-20 16:21:29+00:00   \n",
       "62452  2022-01-20 21:21:47+00:00   \n",
       "\n",
       "                                                   Tweet Stock Name  \\\n",
       "1577   This is extremely important. If people buy the...       TSLA   \n",
       "20620  3/ Fed tightening and Russia/Ukraine tensions ...       TSLA   \n",
       "18621  3/ I remain a $TSLA bull, with a) Berlin/Austi...       TSLA   \n",
       "14884  Just in case something fun happens tonight! $TSLA       TSLA   \n",
       "62452  Spotted:  Ross Gerber watching $NFLX get Chama...       NFLX   \n",
       "\n",
       "        Company Name  \n",
       "1577     Tesla, Inc.  \n",
       "20620    Tesla, Inc.  \n",
       "18621    Tesla, Inc.  \n",
       "14884    Tesla, Inc.  \n",
       "62452  Netflix, Inc.  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df = pd.read_csv(\"data/stock_tweets.csv\")\n",
    "\n",
    "# Text cleanup\n",
    "def clean_tweet(text):\n",
    "    # Remove mentions\n",
    "    text = re.sub(r'@\\w+', '', text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r'#\\w+', '', text)\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(\"\\\\r\" ,'',text)\n",
    "    text = re.sub(\"\\\\n\" ,'',text)\n",
    "    # Remove emojis using Unicode ranges\n",
    "    text = re.sub(r'[\\U0001F600-\\U0001F64F'\n",
    "                  r'\\U0001F300-\\U0001F5FF'\n",
    "                  r'\\U0001F680-\\U0001F6FF'\n",
    "                  r'\\U0001F700-\\U0001F77F'\n",
    "                  r'\\U0001F780-\\U0001F7FF'\n",
    "                  r'\\U0001F800-\\U0001F8FF'\n",
    "                  r'\\U0001F900-\\U0001F9FF'\n",
    "                  r'\\U0001FA00-\\U0001FA6F'\n",
    "                  r'\\U0001FA70-\\U0001FAFF'\n",
    "                  r'\\U00002702-\\U000027B0'\n",
    "                  r'\\U000024C2-\\U0001F251]', '', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Apply the function to the \"tweet\" column\n",
    "tweets_df['Tweet'] = tweets_df['Tweet'].apply(clean_tweet)\n",
    "\n",
    "tweets_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>260.333344</td>\n",
       "      <td>263.043335</td>\n",
       "      <td>258.333344</td>\n",
       "      <td>258.493347</td>\n",
       "      <td>258.493347</td>\n",
       "      <td>53868000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>259.466675</td>\n",
       "      <td>260.260010</td>\n",
       "      <td>254.529999</td>\n",
       "      <td>258.406677</td>\n",
       "      <td>258.406677</td>\n",
       "      <td>51094200</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>265.500000</td>\n",
       "      <td>268.989990</td>\n",
       "      <td>258.706665</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>91449900</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>261.600006</td>\n",
       "      <td>265.769989</td>\n",
       "      <td>258.066681</td>\n",
       "      <td>260.196655</td>\n",
       "      <td>260.196655</td>\n",
       "      <td>55297800</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>258.733337</td>\n",
       "      <td>262.220001</td>\n",
       "      <td>257.739990</td>\n",
       "      <td>260.916656</td>\n",
       "      <td>260.916656</td>\n",
       "      <td>43898400</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>78.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.892000</td>\n",
       "      <td>12.860000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>28279600</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>14.070000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>27891300</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>14.580000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>13.580000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>21160800</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>13.421000</td>\n",
       "      <td>12.690000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>31799400</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>12.110000</td>\n",
       "      <td>12.110000</td>\n",
       "      <td>33044800</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6048 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     2021-09-30  260.333344  263.043335  258.333344  258.493347  258.493347   \n",
       "1     2021-10-01  259.466675  260.260010  254.529999  258.406677  258.406677   \n",
       "2     2021-10-04  265.500000  268.989990  258.706665  260.510010  260.510010   \n",
       "3     2021-10-05  261.600006  265.769989  258.066681  260.196655  260.196655   \n",
       "4     2021-10-06  258.733337  262.220001  257.739990  260.916656  260.916656   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6043  2022-09-23   13.090000   13.892000   12.860000   13.710000   13.710000   \n",
       "6044  2022-09-26   14.280000   14.830000   14.070000   14.370000   14.370000   \n",
       "6045  2022-09-27   14.580000   14.800000   13.580000   13.710000   13.710000   \n",
       "6046  2022-09-28   13.050000   13.421000   12.690000   13.330000   13.330000   \n",
       "6047  2022-09-29   12.550000   12.850000   11.850000   12.110000   12.110000   \n",
       "\n",
       "        Volume Stock Name  Number of Tweets  \n",
       "0     53868000       TSLA              90.0  \n",
       "1     51094200       TSLA              94.0  \n",
       "2     91449900       TSLA             119.0  \n",
       "3     55297800       TSLA              88.0  \n",
       "4     43898400       TSLA              78.0  \n",
       "...        ...        ...               ...  \n",
       "6043  28279600       XPEV               NaN  \n",
       "6044  27891300       XPEV               1.0  \n",
       "6045  21160800       XPEV               NaN  \n",
       "6046  31799400       XPEV               NaN  \n",
       "6047  33044800       XPEV               NaN  \n",
       "\n",
       "[6048 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finance_data = pd.read_csv(\"data/stock_yfinance_data.csv\")\n",
    "tweet_data = pd.read_csv(\"data/stock_tweets.csv\")\n",
    "\n",
    "# Ensure 'Date' columns are in datetime format and only keep the date part\n",
    "finance_data['Date'] = pd.to_datetime(finance_data['Date']).dt.date\n",
    "tweet_data['Date'] = pd.to_datetime(tweet_data['Date']).dt.date\n",
    "\n",
    "# Count tweets per day for each stock\n",
    "tweet_counts = tweet_data.groupby(['Date', 'Stock Name']).size().reset_index(name='Number of Tweets')\n",
    "\n",
    "# Merge tweet_counts with finance_data on Date and Stock Name\n",
    "finance_data = pd.merge(finance_data, tweet_counts, on=['Date', 'Stock Name'], how='left')\n",
    "finance_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "def merge_dataframes(finance_data, sentiment_data, method):\n",
    "    \"\"\"\n",
    "    Processes tweet data to calculate the number of tweets and average sentiment per day,\n",
    "    then merges the results with finance data.\n",
    "\n",
    "    Args:\n",
    "        finance_data (pd.DataFrame): DataFrame containing finance data with 'Date' and 'Stock Name' columns.\n",
    "        tweet_data (pd.DataFrame): DataFrame containing tweet data with 'Date', 'Tweet', and 'Stock Name' columns.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Merged DataFrame with additional columns for the number of tweets and average sentiment.\n",
    "    \"\"\"\n",
    "    \n",
    "        # Ensure 'Date' columns are in datetime format and only keep the date part\n",
    "    finance_data['Stock Name'] = finance_data['Stock Name'].str.strip().str.upper()\n",
    "    sentiment_data['Stock Name'] = sentiment_data['Stock Name'].str.strip().str.upper()\n",
    "    finance_data['Date'] = pd.to_datetime(finance_data['Date']).dt.date\n",
    "    sentiment_data['Date'] = pd.to_datetime(sentiment_data['Date']).dt.date\n",
    "\n",
    "    # Group tweet data by Date and Stock Name to calculate tweet counts and average sentiment\n",
    "    avg_sentiments = sentiment_data.groupby(['Date', 'Stock Name'])['sentiment'].mean().reset_index(name='Average Sentiment')\n",
    "    \n",
    "    # Merge finance data with tweet summary data\n",
    "    merged_df = pd.merge(finance_data, avg_sentiments, on=['Date', 'Stock Name'], how='left')\n",
    "\n",
    "    # Fill NaN values for days with no tweets\n",
    "    merged_df['Number of Tweets'] = merged_df['Number of Tweets'].fillna(0)\n",
    "    merged_df['Average Sentiment'] = merged_df['Average Sentiment'].fillna(0)\n",
    "\n",
    "    # Drop rows with NaN values in critical columns\n",
    "    merged_df = merged_df.dropna(subset=['Close'])\n",
    "    \n",
    "    merged_df.to_csv(f\"data/cleaned_data_{method}.csv\")\n",
    "\n",
    "    return merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69759/69759 [00:07<00:00, 9851.24it/s] \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Name</th>\n",
       "      <th>Number of Tweets</th>\n",
       "      <th>Average Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-30</td>\n",
       "      <td>260.333344</td>\n",
       "      <td>263.043335</td>\n",
       "      <td>258.333344</td>\n",
       "      <td>258.493347</td>\n",
       "      <td>258.493347</td>\n",
       "      <td>53868000</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>90.0</td>\n",
       "      <td>0.202088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-10-01</td>\n",
       "      <td>259.466675</td>\n",
       "      <td>260.260010</td>\n",
       "      <td>254.529999</td>\n",
       "      <td>258.406677</td>\n",
       "      <td>258.406677</td>\n",
       "      <td>51094200</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.216879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>265.500000</td>\n",
       "      <td>268.989990</td>\n",
       "      <td>258.706665</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>260.510010</td>\n",
       "      <td>91449900</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.125718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>261.600006</td>\n",
       "      <td>265.769989</td>\n",
       "      <td>258.066681</td>\n",
       "      <td>260.196655</td>\n",
       "      <td>260.196655</td>\n",
       "      <td>55297800</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.091361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>258.733337</td>\n",
       "      <td>262.220001</td>\n",
       "      <td>257.739990</td>\n",
       "      <td>260.916656</td>\n",
       "      <td>260.916656</td>\n",
       "      <td>43898400</td>\n",
       "      <td>TSLA</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.210363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>2022-09-23</td>\n",
       "      <td>13.090000</td>\n",
       "      <td>13.892000</td>\n",
       "      <td>12.860000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>28279600</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6044</th>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>14.280000</td>\n",
       "      <td>14.830000</td>\n",
       "      <td>14.070000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>14.370000</td>\n",
       "      <td>27891300</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6045</th>\n",
       "      <td>2022-09-27</td>\n",
       "      <td>14.580000</td>\n",
       "      <td>14.800000</td>\n",
       "      <td>13.580000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>13.710000</td>\n",
       "      <td>21160800</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6046</th>\n",
       "      <td>2022-09-28</td>\n",
       "      <td>13.050000</td>\n",
       "      <td>13.421000</td>\n",
       "      <td>12.690000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>13.330000</td>\n",
       "      <td>31799400</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6047</th>\n",
       "      <td>2022-09-29</td>\n",
       "      <td>12.550000</td>\n",
       "      <td>12.850000</td>\n",
       "      <td>11.850000</td>\n",
       "      <td>12.110000</td>\n",
       "      <td>12.110000</td>\n",
       "      <td>33044800</td>\n",
       "      <td>XPEV</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6048 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        Open        High         Low       Close   Adj Close  \\\n",
       "0     2021-09-30  260.333344  263.043335  258.333344  258.493347  258.493347   \n",
       "1     2021-10-01  259.466675  260.260010  254.529999  258.406677  258.406677   \n",
       "2     2021-10-04  265.500000  268.989990  258.706665  260.510010  260.510010   \n",
       "3     2021-10-05  261.600006  265.769989  258.066681  260.196655  260.196655   \n",
       "4     2021-10-06  258.733337  262.220001  257.739990  260.916656  260.916656   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "6043  2022-09-23   13.090000   13.892000   12.860000   13.710000   13.710000   \n",
       "6044  2022-09-26   14.280000   14.830000   14.070000   14.370000   14.370000   \n",
       "6045  2022-09-27   14.580000   14.800000   13.580000   13.710000   13.710000   \n",
       "6046  2022-09-28   13.050000   13.421000   12.690000   13.330000   13.330000   \n",
       "6047  2022-09-29   12.550000   12.850000   11.850000   12.110000   12.110000   \n",
       "\n",
       "        Volume Stock Name  Number of Tweets  Average Sentiment  \n",
       "0     53868000       TSLA              90.0           0.202088  \n",
       "1     51094200       TSLA              94.0           0.216879  \n",
       "2     91449900       TSLA             119.0           0.125718  \n",
       "3     55297800       TSLA              88.0           0.091361  \n",
       "4     43898400       TSLA              78.0           0.210363  \n",
       "...        ...        ...               ...                ...  \n",
       "6043  28279600       XPEV               0.0           0.000000  \n",
       "6044  27891300       XPEV               1.0           0.585900  \n",
       "6045  21160800       XPEV               0.0           0.000000  \n",
       "6046  31799400       XPEV               0.0           0.000000  \n",
       "6047  33044800       XPEV               0.0           0.000000  \n",
       "\n",
       "[6048 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "sentiment = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment_score(text):\n",
    "    return sentiment.polarity_scores(text)['compound']\n",
    "\n",
    "tweets_df_vader = tweets_df.copy()\n",
    "\n",
    "tweets_df_vader['sentiment'] = tweets_df_vader['Tweet'].progress_apply(get_sentiment_score)\n",
    "\n",
    "merge_dataframes(finance_data, tweets_df_vader, \"vader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_financial_tweet(tweet):\n",
    "    # Financial keywords\n",
    "\n",
    "    financial_keywords = [\n",
    "        'stock', 'market', 'trading', 'shares', 'portfolio', 'revenue',\n",
    "        'profit', 'loss', 'growth', 'inflation', 'interest', 'rate', \n",
    "        'dividend', 'crypto', 'bitcoin', 'Fed', 'IPO', 'earnings', 'forecast', \n",
    "        'guidance', 'EBITDA', 'margin', 'cash flow', 'assets', 'liabilities', \n",
    "        'stock price', 'valuation', 'P/E ratio', 'EPS', 'dividend', \n",
    "        'market cap', 'volatility', 'quarterly report', 'earnings call', \n",
    "        'share buyback', 'merger', 'acquisition', 'upgrade', 'downgrade', 'estimates', '$',\n",
    "        'interest', 'debt', 'decline', 'net income', 'gross income', 'operating income', 'bull', \n",
    "        'bullish', 'bear', 'bearish', 'green', 'red', 'security', 'securities'\n",
    "    ]\n",
    "\n",
    "    for i in financial_keywords:\n",
    "        if i.lower() in tweet.lower():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "emoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\n",
      "100%|██████████| 69759/69759 [1:19:01<00:00, 14.71it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "\n",
    "# Enable tqdm for pandas\n",
    "tqdm.pandas()\n",
    "\n",
    "# Load FinBERT model and tokenizer\n",
    "tokenizer_finance = AutoTokenizer.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "model_finance = AutoModelForSequenceClassification.from_pretrained(\"yiyanghkust/finbert-tone\")\n",
    "nlp_finance = pipeline(\"sentiment-analysis\", model=model_finance, tokenizer=tokenizer_finance)\n",
    "\n",
    "# Load general sentiment model\n",
    "nlp_general = pipeline(\"sentiment-analysis\", model=\"finiteautomata/bertweet-base-sentiment-analysis\")\n",
    "\n",
    "# Define the function for analyzing sentiment\n",
    "def analyze_batch(tweets):\n",
    "    results = []\n",
    "    for tweet in tweets:\n",
    "        if is_financial_tweet(tweet):\n",
    "            result = nlp_finance(tweet)[0]\n",
    "        else:\n",
    "            result = nlp_general(tweet)[0]\n",
    "\n",
    "        score, label = result[\"score\"], result[\"label\"]\n",
    "        sentiment = {\n",
    "            \"Positive\": score,\n",
    "            \"Negative\": -score,\n",
    "            \"Neutral\": round(1 - score, 4),\n",
    "            \"POS\": score,\n",
    "            \"NEG\": -score,\n",
    "        }.get(label, 0)\n",
    "        results.append(sentiment)\n",
    "    return results\n",
    "\n",
    "# Apply in batches\n",
    "batch_size = 32\n",
    "tweets_df_bert = tweets_df.copy()\n",
    "tweets_df_bert['sentiment'] = tweets_df_bert['Tweet'].progress_apply(\n",
    "    lambda x: analyze_batch([x])[0]  # Single row\n",
    ")\n",
    "\n",
    "merge_dataframes(finance_data, tweets_df_bert, \"bert\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
